{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0801f96f",
   "metadata": {},
   "source": [
    "# Using LLMChain\n",
    "The LLMChain is most basic building block chain. It takes in a prompt template, formats it with the user input and returns the response from an LLM.\n",
    "\n",
    "To use the LLMChain, first create a prompt template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d84176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=\"OpenAPIkey\")\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2e9e0",
   "metadata": {},
   "source": [
    "We can now create a very simple chain that will take user input, format the prompt with it, and then send it to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcfc79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Socktastic!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6022f",
   "metadata": {},
   "source": [
    "If there are multiple variables, you can input them all at once using a dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c0e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Socktastic!\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"company\", \"product\"],\n",
    "    template=\"What is a good name for {company} that makes {product}?\",\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run({\n",
    "    'company': \"ABC Startup\",\n",
    "    'product': \"colorful socks\"\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b002ac",
   "metadata": {},
   "source": [
    "You can use a chat model in an LLMChain as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e157134f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainbow Socks Co.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=\"OpenAPIkey\")\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "print(chain.run(\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c257f",
   "metadata": {},
   "source": [
    "# Math chain\n",
    "This notebook showcases using LLMs and Python REPLs to do complex word math problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847e3dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m\n",
      "```text\n",
      "13**.3432\n",
      "```\n",
      "...numexpr.evaluate(\"13**.3432\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: 2.4116004626599237'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, LLMMathChain\n",
    "\n",
    "llm = OpenAI(temperature=0,  openai_api_key=\"OpenAPIkey\")\n",
    "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
    "\n",
    "llm_math.run(\"What is 13 raised to the .3432 power?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62e039",
   "metadata": {},
   "source": [
    "# Bash chain\n",
    "This notebook showcases using LLMs and a bash process to perform simple filesystem commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3437c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Please write a bash script that prints 'Hello World' to the console.\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "```bash\n",
      "echo \"Hello World\"\n",
      "```\u001b[0m\n",
      "Code: \u001b[33;1m\u001b[1;3m['echo \"Hello World\"']\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m\"Hello World\"\n",
      "\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Hello World\"\\r\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMBashChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0,openai_api_key=\"OpenAPIkey\")\n",
    "\n",
    "text = \"Please write a bash script that prints 'Hello World' to the console.\"\n",
    "\n",
    "bash_chain = LLMBashChain.from_llm(llm, verbose=True)\n",
    "\n",
    "bash_chain.run(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99dc67f",
   "metadata": {},
   "source": [
    "# Router\n",
    "This notebook demonstrates how to use the RouterChain paradigm to create a chain that dynamically selects the next chain to use for a given input.\n",
    "\n",
    "Router chains are made up of two components:\n",
    "\n",
    "The RouterChain itself (responsible for selecting the next chain to call)\n",
    "destination_chains: chains that the router chain can route to\n",
    "In this notebook we will focus on the different types of routing chains. We will show these routing chains used in a MultiPromptChain to create a question-answering chain that selects the prompt which is most relevant for a given question, and then answers the question using that prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c653ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60804742",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d20a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Good for answering questions about physics\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering math questions\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63452014",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0,openai_api_key=\"OpenAPIkey\")\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56cbc0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Gravity is a force of attraction between two objects that is proportional to their masses and inversely proportional to the square of the distance between them. It is the force that causes objects to fall to the ground when dropped and is the force that keeps the planets in orbit around the sun.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is gravity?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d47fe323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "The first prime number greater than 40 such that one plus the prime number is divisible by 3 is 43.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.run(\n",
    "        \"What is the first prime number greater than 40 such that one plus the prime number is divisible by 3\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde5dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
